# -*- coding: utf-8 -*-
"""KNN_trail.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f1xh89R3EneLa20qN34tltrMr3BaP54R
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/gdrive')

import sqlite3
con = sqlite3.connect('/content/gdrive/My Drive/database.sqlite')

filtered_data=pd.read_sql_query("""
SELECT * 
FROM REVIEWS
WHERE Score != 3 limit 100000""",con)
print(filtered_data.shape)

y=filtered_data['Score']
y=y[:100000][:]

x= filtered_data['Text']
print(len(x))
type(x)

y=y[:100000]
len(y)
print(y.head())

for i in range(len(y)):
  if y[i]<3:
    y[i]=0
  else:
    y[i]=1
print(y.head())

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33) #splitting the train  and test

x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.33) # this is random splitting

print(x_train.shape, y_train.shape)
print(x_cv.shape, y_cv.shape)
print(x_test.shape, y_test.shape)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(ngram_range=(1,2))

tfidf_fit = tfidf.fit(x_train)

x_train_tfidf = tfidf.transform(x_train)
x_cv_tfidf = tfidf.transform(x_cv)
x_test_tfidf = tfidf.transform(x_test)

print(x_train_tfidf.shape, y_train.shape)
print(x_cv_tfidf.shape, y_cv.shape)
print(x_test_tfidf.shape, y_test.shape)

"""# Hyper parameter Tuning"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score

import matplotlib.pyplot as plt

y_cv = y_cv.astype(int)
y_train = y_train.astype(int)
y_test = y_test.astype(int)

x_train_auc =[]
x_cv_auc = []
k = [1,5,10,15,20,25,30,35,45,55]
#k = [5]
for i in k:
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(x_train_tfidf, y_train)
  y_train_pred = neigh.predict_proba(x_train_tfidf)[:,1]
  y_cv_pred = neigh.predict_proba(x_cv_tfidf)[:,1]
  x_train_auc.append(roc_auc_score(y_train, y_train_pred))
  x_cv_auc.append(roc_auc_score(y_cv, y_cv_pred))



plt.plot(k, x_train_auc, label='Train AUC')
plt.plot(k, x_cv_auc, label="CV AUC")
plt.legend()
plt.xlabel("K: hyperparameter")
plt.ylabel("AUC")
plt.title("Accuracy plot")
plt.show()

best_k = 15

# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve
from sklearn.metrics import roc_curve, auc


neigh = KNeighborsClassifier(n_neighbors=best_k)
neigh.fit(x_train_tfidf, y_train)
# roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class
# not the predicted outputs

train_fpr, train_tpr, thresholds = roc_curve(y_train, neigh.predict_proba(x_train_tfidf)[:,1])
test_fpr, test_tpr, thresholds = roc_curve(y_test, neigh.predict_proba(x_test_tfidf)[:,1])

plt.plot(train_fpr, train_tpr, label="train AUC ="+str(auc(train_fpr, train_tpr)))
plt.plot(test_fpr, test_tpr, label="test AUC ="+str(auc(test_fpr, test_tpr)))
plt.legend()
plt.xlabel("K: hyperparameter")
plt.ylabel("AUC")
plt.title("ERROR PLOTS")
plt.show()

print("="*100)
from sklearn.metrics import confusion_matrix
print("Train confusion matrix")
print(confusion_matrix(y_train, neigh.predict(x_train_tfidf)))
print("Test confusion matrix")
print(confusion_matrix(y_test, neigh.predict(x_test_tfidf)))



